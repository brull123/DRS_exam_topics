\documentclass[../exam_questions.tex]{subfiles}

\begin{document}

\lecture{Lecture 14} % Video lectures 12-13
% -------------------------------------------------------------------------
\section{Define the consensus/synchronization problem in states and outputs. Explain the difference between homogeneous and heterogeneous agents.}
\begin{definition}{Consensus/synchronization problem}{}
	The goal is to reach a state or output consensus
	\begin{align}
		||x_i - x_j|| & \rightarrow 0, \: {\rm for}\: t\rightarrow \infty, \:{\rm or} \\
		||y_i - y_j|| & \rightarrow 0, \: {\rm for}\: t\rightarrow \infty.
	\end{align}
	In case of leader following the problem is defined as
	\begin{align}
		||x_i - x_0|| & \rightarrow 0, \: {\rm for}\: t\rightarrow \infty, \: {\rm or} \\
		||y_i - y_0|| & \rightarrow 0, \: {\rm for}\: t\rightarrow \infty,
	\end{align}
	where the leader is uncontrolled
	\begin{align}
		\dot{x}_0 & = A x_0 \\
		y_0       & = C x_0
	\end{align}
\end{definition}
\begin{definition}{Consensus}{}
	Consensus is a state which is constant. After reaching the consensus, the agents remain it such state indefinitely.
\end{definition}

\begin{definition}{Synchronization}{}
	If agents are synchronized, they have reached a common state, which evolves in time. After achieving synchronization,
	the agents' states still evolve, but all in the same manner.
\end{definition}

\begin{definition}{Agents}{}
	Agents are autonomous subsystems, with dynamics having a state description generally in $\R^n$ - $x_i \in \R^{n_i}, \: i = 1,\dots, N$.
	Agents are assumed to have local computation and communication capabilities.
\end{definition}
\subsection{Homogeneous agents}
Each of the agents can be described by a general LTI system
\begin{align}
	\dot{x}_i & = Ax_i + Bu_i \\
	y_i       & = Cx_i + Du_i
\end{align}
In general the systems may not be LTI
\begin{align}
	\dot{x}_i & = f(x_i, u_i)  \\
	y_i       & = h(x_i, u_i).
\end{align}

The control problem for an multi-agent system is asymptotic state synchronization
\begin{align}
	||x_i - x_j|| \rightarrow 0, \: \forall (i, j) \: {\rm as} \: t \rightarrow \infty
\end{align}

\pagebreak
\subsection{Heterogeneous agents}
Heterogeneous agents assume that systems of individual agents may differ from each other, their states may differ in dimensions $x_i \in \R^{n_i},\: n_i \neq n_j$
and therefore the state synchronization problem cannot be posed. Even if the dimensions were the same, the state variables may be different and it would make no sense to synchronize such different state variables.

In the case of LTI systems
\begin{align}
	\dot{x}_i & = A_i x_i + B_i u_i  \\
	y_i       & = C_i x_i + D_i u_i.
\end{align}

In general, the state-state equations are
\begin{align}
	\dot{x}_i & = f_i(x_i, u_i)  \\
	y_i       & = h_i(x_i, u_i).
\end{align}

Instead, the control goal is asymptotic synchronization of outputs.
\begin{align}
	||y_i - y_j|| \rightarrow 0, \: \forall (i, j) \: {\rm as} \: t \rightarrow \infty
\end{align}

% -------------------------------------------------------------------------
\section{Write the single-integrator leaderless consensus dynamics in continuous time. How to include a leader?}
The single-integrator agents have a dynamic model
\begin{align}
	\dot{x}_i = u_i,
\end{align}
with local neighborhood error in the states for control,
\begin{align}
	u_i & = \sum_{j} e_{ij}(x_j - x_i),
\end{align}
where $e_{ij}$ are the elements of the adjacency matrix $E$. The standard notation conflicts with state-space matrix $A$.
The elements can either be binary to signify which agents are connected to which or they can be weights.

The control input is available to each single-agent in a distributed way. This results in a closed-loop system
\begin{align}
	\dot{x}_i & = \sum_j e_{ij}(x_j - x_i) \\
\end{align}

For every edge from/to agent $x_i$ (there are $d_i$ in total) the control input subtracts its value and for every neighbouring state its value is added.
Which can be written as
\begin{align}
	u_i & = - d_i x_i + \sum_j e_{ij} x_j.
\end{align}

This can be written in matrix notation using the Laplacian
\begin{align}
	\dot{x} & = - (D - E) x,\: \text{ where $x$ is the multi-agent state vector} \\
	\dot{x} & = - L x                                                            \\
	x       & = \begin{bmatrix}
		            x_1 & x_2 & \dots & x_N
	            \end{bmatrix}^T
\end{align}

\subsection{Leader - Pinning control}
A leader is an uncontrolled agent
\begin{align}
	\dot{x}_0 & = A x_0  \\
	y_0       & = C x_0.
\end{align}

The control of other agents is augmented with a non-negative pinning gain
\begin{align}
	g_i(x_0 - x_i),
\end{align}
where $g_i$ can be either binary element signifying whether the $i^{\rm th}$ agent is connected to the leader or it can be a control gain same as with $e_{ij}$.
Usually $g_i$ is nonzero only for a small fraction of nodes. The following of the leader is then propagated through the graph structure to
other vertices.

The total control input is then
\begin{align}
	\dot{x}_i & = A x_i + BK \left[\sum_j e_{ij} (x_j - x_i) + g_i (x_0 - x_i)\right],
\end{align}
which can again be written in matrix notation
\begin{align}
	\dot{x} & = - (L + G) (x - \bm{1}_N x_0).
\end{align}

We can define a synchronization error
\begin{align}
	\delta_i     & = x_i - x_0        \\
	\dot{\delta} & = -(L + G) \delta.
\end{align}

The matrix $(L+G)$ is nonsingular and all eigenvalues have positive real part, therefore with pinning control, the synchronization will be achieved asymptotically.

% -------------------------------------------------------------------------
\section{Write the single-integrator leaderless consensus dynamics in discrete time. How to include a leader?}
In discrete time the model of a single agent is
\begin{align}
	x_i(k+1) & = u_i(k)
\end{align}
or in an alternative way
\begin{align}
	x_i(k+1) & = x_i(k) + \tilde{u}_i(k).
\end{align}
In the first case, an uncontrolled system would immediately go to zero. In the latter, the uncontrolled system will
retain its value.

The consensus is reached by calculating the weighted average of the current state and the state of all neighbors.
\begin{align}
	u_i(k) & = \frac{1}{d_i+1} \left[x_i(k) + \sum_{j} e_{ij} x_j(k)\right],
\end{align}
where $e_{ij}$ are elements of the adjacency matrix $E$.
In compact notation the closed loop system is
\begin{align}
	x(k+1) & = (I + D)^{-1} (I + E)x(k),
\end{align}
where $D = diag(d_i)$. If the graph has a spanning tree - if it is strongly connected, it will eventually converge to consensus.

Perhaps a clearer way to write the equation using the second definition of the input
\begin{align}
	x_i(k+1)       & = x_i(k) + \tilde{u}_i(k)                                       \\
	\tilde{u}_i(k) & = - \frac{1}{1+d_i} \sum_j e_{ij} \left[x_i(k) - x_j(k)\right].
\end{align}
In matrix notation it can be rewritten using the Laplacian
\begin{align}
	x(k+1)       & = x(k) + \tilde{u}(k)     \\
	\tilde{u}(k) & = - (I + D)^{-1} L x (k).
\end{align}

\subsection{Leader}
We add a leader as a term of the weighted average
\begin{align}
	x_i(k+1) & = \frac{1}{1 + d_i + g_i} \left[x_i(k) + g_ix_0 + \sum_{j} e_{ij} x_j(k)\right].
\end{align}
In matrix notation that would be
\begin{align}
	x(k+1) & = (I + D + G)^{-1} \left[(I + E)x(k) + G \bm{1} x_0\right].
\end{align}

In discrete time, we can also define synchronization error
\begin{align}
	\delta_i(k) & = x_i(k) - x(0)
	\delta(k+1) & = (I + D + G)^{1} (I + E)\delta(k).
\end{align}
The system is asymptotically stable if the graph of followers is pinned to the root of a spanning tree or more generally to all roots of a spanning forest.

% -------------------------------------------------------------------------
% Video lecture 13
\section{Set up the dynamical equations for continuous-time homogeneous LTI agents using local neighborhood error signal for state synchronization.}
A single agent has dynamics
\begin{align}
	\dot{x}_i & = A x_i + B u_i \\
	y_i       & = C x_i.
\end{align}
The agents are homogeneous and therefore the matrices $A, B, C, D$ are the same for every agent.
The goal is either $\lVert x_i  - x_j\rVert \rightarrow 0$ in case there is no leader present, or if there is a leader present then
the goal is $||x_i - x_0|| \rightarrow 0$.

We assume that the leader is uncontrolled
\begin{align}
	\dot{x}_0 & = Ax_0  \\
	y_0       & = Cx_0.
\end{align}

For leaderless configuration the control input is
\begin{align}
	u_i       & = K \left[\sum_j e_{ij}(x_j - x_i)\right]          \\
	\dot{x}_i & = Ax_i + BK \left[\sum_j e_{ij}(x_j - x_i)\right],
\end{align}
where $K$ is a control gain. Unlike in single-integrator systems, here $x_i \in \R^n$, where $n$ is the order of a single agent.

With leader following there is an addition of a pinning control
\begin{align}
	u_i       & = K\left[\sum_j e_{ij}(x_j - x_i) + g_i(x_0 - x_i)\right]           \\
	\dot{x}_i & = Ax_i + BK \left[\sum_j e_{ij}(x_j - x_i) + g_i(x_0 - x_i)\right],
\end{align}

In vector notation that is
\begin{align}
	\bm{x} & =
	\begin{bmatrix}
		x_1    \\
		\vdots \\
		x_N    \\
	\end{bmatrix} \in \R^{nN}, \: x_i \in R^n \\
	\bm{u} & =
	\begin{bmatrix}
		u_1    \\
		\vdots \\
		u_N
	\end{bmatrix} \in \R^{mN}, \: u_i \in R^m.
\end{align}
With the use of Kronecker multiplication
\begin{align}
	I_n                            & \in \R^{n \times n}, \: I_p \in \R^{p \times p},\: A \in \R^{p \times p}, \: B \in \R^{n \times n} \\
	I \otimes A                    & =
	\begin{bmatrix}
		A &        &   \\
		  & \ddots &   \\
		  &        & A
	\end{bmatrix} \in \R^{np \times np}                                                                                                 \\
	A \otimes I                    & =
	\begin{bmatrix}
		a_{11} I & \dots  & a_{1p} I \\
		\vdots   & \ddots & \vdots   \\
		a_{p1} I & \dots  & a_{pp} I
	\end{bmatrix} \in \R^{pn \times pn}                                                                                                 \\
	(I_n \otimes A)(B \otimes I_p) & = B \otimes A
\end{align}

The local neighborhood error can be written as one of the two following options
\begin{align}
	L \otimes I \bm{x} \\
	(L + G) \otimes I \bm{x}.
\end{align}
We can then write the control input $u$ as
\begin{align}
	\bm{u}            & =
	\begin{cases}
		-(I \otimes K)(L \otimes I) \bm{x} = - L \otimes K \bm{x}\: \text{for swarming} \\
		-(I \otimes K)((L+G) \otimes I) \bm{x} = - (L+G) \otimes K (\bm{x} - \bm{1} \otimes x_0)\: \text{for leader following}
	\end{cases} \\
	\bm{\dot{x}}      & = \left[(I_N \otimes A) - c L \otimes BK\right] \bm{x}                                            \\
	\bm{\dot{\delta}} & = \left[(I_N \otimes A) - c (L+G) \otimes BK\right] \bm{\delta},
\end{align}
where $c>0$ is a scalar gain. We design the gain $K$ based on the dynamics of a single agent and the scalar gain $c$ based on the graph topology.
The total system dynamic matrix has size $\R^{mN \times nN}$.

% -------------------------------------------------------------------------
\section{Show how to use complex matrix pencils for investigating state synchronization of homogeneous agents.}
\begin{warningbox}
	Proof/Derivation is required as a part of the exam
\end{warningbox}

We are looking for a transformation $T$
\begin{align}
	T^{-1} L T     & = \Lambda\\
	T^{-1} (L+G) T & = \Lambda,
\end{align}
where $\Lambda$ is triangular. The analysis is the same for both cases, so I will continue with swarming.

If we apply such transformation on the system dynamic matrix we get
\begin{align}
	(T^{-1} \otimes I_n) (I_N \otimes A - c L \otimes B K)(T \otimes I_n).
\end{align}
The Kronecker multiplication properties give
\begin{align}
	T^{-1}T \otimes A - c T^{-1} L T \otimes B K \\
	I_n \otimes A - c\Lambda  \otimes B K
\end{align}
The resulting matrix has triangular blocks on the diagonal. The blocks are
\begin{align}
	A - c \Lambda_{ii} B K \in \R^{n\times n}.
\end{align}

Now we can analyze $N$ matrices of lower dimensionality then before. The eigenvalues of the blocks are the eigenvalues of the whole matrix. If the eigenvalues of theses blocks are stable, we can
conclude that the whole system is stable.

The diagonal elements of $\Lambda_{ii}$ are the eigenvalues of the graph Laplacian.
One is zero and the other ones have non-negative real part. If the graph has a spanning tree, then the other eigenvalues have strictly positive real part.

The matrices on the block diagonal are $A - c \lambda_i B K \in \mathbb{C}^{n \times n}$.
We can now ignore the graph topology and only analyze the stability of the matrix pencil.
A metric pencil is a matrix polynomial of the first degree. In our case a polynomial of variable $\sigma \in \mathbb{C}$ with matrix coefficients.
The matrix pencil is
\begin{align}
	A -  \sigma B K.
\end{align}
For which $\sigma$ is the matrix asymptotically stable. These create the synchronizing region.

We want to find a feedback gain $K$ which stabilizes a single agent - we want to maximize the synchronizing region of a single agent. Then we want to find a scalar gain $c > 0$ which
scales the eigenvalues of the graph Laplacian into the synchronizing region.

We require $(A,B)$ stabilizeable.
Also that $(A-BK)$ asymptotically stable for $\sigma = 1$ - that is there exists a $K$ such that $\sigma = 1$ is in the synchronizing region.

% -------------------------------------------------------------------------
\pagebreak
\section{Show that with the distributed feedback gain designed from the single-agent Algebraic Riccati Equation the resulting synchronizing region is an unbounded left-hand half-plane in the complex plane.}
\begin{warningbox}
	Proof/Derivation is required as a part of the exam
\end{warningbox}

\subsection{Lyapunov analysis}
For continuous time the Lyapunov function is
\begin{align}
	V(z) & = z^{\dagger} P z,\: z \in \mathbb{C}, \: P = P^T \succ 0,\: P \in \R^{n \times n}.
\end{align}
Here $z^{\dagger}$ stands for Hermitian adjoint - transposed and complex conjugate.
\begin{align}
	z            & = \begin{bmatrix}
		                 z_1    \\
		                 \vdots \\
		                 z_n
	                 \end{bmatrix}, \:
	z^{\dagger} =
	\begin{bmatrix}
		\bar{z}_1 & \dots & \bar{z}_n
	\end{bmatrix}, \:{\rm where}                                               \\
	z_i          & = a + bi, \: \bar{z}_i = a - bi                              \\
	z^{\dagger}z & = \sum_i \bar{z}_i z_i = \sum_i |z_i|^2 = \lVert z \rVert^2.
\end{align}

The time derivative of the Lyapunov function is
\begin{align}
	\dot{V} & = z^{\dagger}\left[\left(A - \sigma B K \right)^{\dagger} P + P \left(A - \sigma B K \right)\right]z.
\end{align}

The matrix can be modified to obtain
\begin{align}
	\left(A - \sigma B K\right)^{\dagger} P + P \left(A - \sigma B K \right) & = A^T P + P A -(\sigma B K)^{\dagger} P - P (\sigma B K)                                     \\
	                                                                         & = A^T P + P A - K^T B^T \bar{\sigma}^T P - P \sigma B K.                    \label{eq:input}
\end{align}
We chose the feedback gain
\begin{align}
	K & = R^{-1} B^T P
\end{align}
And substitute into \eqref{eq:input}
\begin{align}
	\left(A - \sigma B K\right)^{\dagger} P + P \left(A - \sigma B K \right) & = A^T P + P A - (R^{-1} B^T P)^T B^T \bar{\sigma}^T P - P \sigma B R^{-1} B^T P \\
	                                                                         & = A^T P + P A - P B R^{-1} B^T \bar{\sigma}^T P - \sigma P B R^{-1} B^T P       \\
	                                                                         & = A^T P + P A - (\bar{\sigma}^T + \sigma) P B R^{-1} B^T P.
\end{align}
Since $\sigma \in \mathbb{C}$ is a scalar complex number, the transpose is equal to itself.
\begin{align}
	\left(A - \sigma B K\right)^{\dagger} P + P \left(A - \sigma B K \right) & = A^T P + P A - (\bar{\sigma} + \sigma) P B R^{-1} B^T P                \\
	                                                                         & = A^T P + P A - 2\Re(\sigma) P B R^{-1} B^T P                           \\
	                                                                         & = A^T P + P A - P B R^{-1} B^T P + (1 - 2\Re(\sigma)) P B R^{-1} B^T P.
\end{align}
Now we substitute from ARE
\begin{align}
	A^T P + P A + Q - P B^{-1} R B^T P & = 0   \\
	A^T P + P A - P B^{-1} R B^T P     & = -Q.
\end{align}
We obtain
\begin{align}
	\left(A - \sigma B K\right)^{\dagger} P + P \left(A - \sigma B K \right) & =
	-Q +(1 - 2\Re(\sigma)) P B R^{-1} B^T P.
\end{align}
The resulting matrix is negative definite for $\Re (\sigma) > \frac{1}{2}$ meaning the synchronizing region is a right half-plane.

Every positive eigenvalue of the graph Laplacian can be multiplied by $c$ such that
\begin{align}
	c~\Re({\lambda_i})~>~\Re({\sigma})~>~\frac{1}{2}.
\end{align}
This gives us that the scalar gain $c$ needs to satisfy
\begin{align}
	c > \frac{1}{2 \Re{(\min \lambda_i(L)_{>0})}}.
\end{align}
In case of leader following
\begin{align}
	c > \frac{1}{2 \Re{(\min \lambda_i(L+G))}}.
\end{align}
The condition is only a sufficient condition, in fact the stabilizing region is a bit larger.
Fig. \ref{fig:synchronizing_region} show an example of the synchronizing region.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{Figures/synchronizing_region.png}
	\caption{Synchronizing region}
	\label{fig:synchronizing_region}
\end{figure}
\pagebreak
% % -------------------------------------------------------------------------
\section{What are the necessary topological conditions on the communication graph for consensus or synchronization? Explain the dynamical role of the Fiedler eigenvalue in continuous time single integrator consensus.}
The control input of a single integrator system for each vertex is $\dot{x} = - Lx$.
The dynamics of the system is given by the graph Laplacian - if every eigenvalue (other then the 0) of the Laplacian has
positive real part (the eigenvalues of -L need to be negative), the system will reach consensus. The zero eigenvalue corresponds to the consensus vector $L\bm{1} = 0$.
If more than one eigenvalues are zero, the graph does not have a spanning tree and therefore there are at least two connected components which are not connected together.
Each of the components will reach its own consensus but there will not be a common consensus.
If the graph is weakly connected, then each of the strongly connected components will reach its own consensus and then slowly
all vertices will reach a common consensus.

The rate of convergence is given by the second smallest eigenvalue - the Fiedler eigenvalue.

\end{document}